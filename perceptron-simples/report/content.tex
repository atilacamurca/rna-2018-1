% pandoc-fignos: caption name
\renewcommand{\figurename}{Figura}

\section{Introdução}

Em 1943 McCulloch e Pitts propuseram um modelo matemático para o
neurônio biológico. A ideia era ter uma forma computacional para dado um
conjunto de entrada poder ser calculado uma saída. Entretanto era
necessário obter os chamados pesos sinápticos de alguma forma. Daí em
1958 Rosenblatt propôs um algoritmo chamado Perceptron Simples. Esse
algoritmo consiste do neurônio de McCulloch e Pitts com uma regra de
aprendizagem.

\section{Problemas}

\subsection{Artificial I}

Para o problema Artificial I foi gerado uma base no seguinte formato:

\begin{itemize}
\tightlist
\item
  Para valores entre
  \((0 : 0.2; 0 : 0.2), (0 : 0.2; 0.5 : 1), (0.5 : 1; 0 : 0.2)\) é
  considerado classe 0, com 30 itens na base;
\item
  Para valores entre \((0.5 : 1; 0.5 : 1)\) é considerado classe 1, com
  10 itens na base.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ClasseZero = [}
    \CommentTok{% 0 0}
    \FunctionTok{rand}\NormalTok{(}\FloatTok{10}\NormalTok{, }\FloatTok{1}\NormalTok{) .* }\FloatTok{0.2} \FunctionTok{rand}\NormalTok{(}\FloatTok{10}\NormalTok{, }\FloatTok{1}\NormalTok{) .* }\FloatTok{0.2}\NormalTok{;}
    \CommentTok{% 0 1}
    \FunctionTok{rand}\NormalTok{(}\FloatTok{10}\NormalTok{, }\FloatTok{1}\NormalTok{) .* }\FloatTok{0.2} \FunctionTok{rand}\NormalTok{(}\FloatTok{10}\NormalTok{, }\FloatTok{1}\NormalTok{) .* }\FloatTok{0.5}\NormalTok{ + }\FloatTok{0.5}\NormalTok{;}
    \CommentTok{% 1 0}
    \FunctionTok{rand}\NormalTok{(}\FloatTok{10}\NormalTok{, }\FloatTok{1}\NormalTok{) .* }\FloatTok{0.5}\NormalTok{ + }\FloatTok{0.5} \FunctionTok{rand}\NormalTok{(}\FloatTok{10}\NormalTok{, }\FloatTok{1}\NormalTok{) .* }\FloatTok{0.2}\NormalTok{;}
\NormalTok{];}
\NormalTok{ClasseOne = }\FunctionTok{rand}\NormalTok{(}\FloatTok{10}\NormalTok{, }\FloatTok{2}\NormalTok{) .* }\FloatTok{0.5}\NormalTok{ + }\FloatTok{0.5}\NormalTok{;}
\end{Highlighting}
\end{Shaded}

\subsection{Íris}

O problema da Íris é a classificação de uma espécie de flor. Essa base
de dados é formada por 3 categorias: Setosa, Versicolor e Virgínica.
Como o Perceptron Simples não é capaz de classificar problemas não
binários foi necessário adaptar o problema para classificação de: Setosa
ou Outra, onde:

\begin{itemize}
\tightlist
\item
  Setosa é classificada como classe 1 (um), com 40 itens na base;
\item
  Enquanto outras são classificadas com classe 0 (zero), com 80 itens na
  base.
\end{itemize}

\section{Resultados}

\subsection{Artificial I}

Ao longo de várias execuções foram encontrados resultados sempre acima
de 95\% de acurária. Em alguns dos testes chegou a 100\% de acurácia.

Em testes em que houve erros, tivemos por exemplo a Matrix de Confusão:

\[
\begin{bmatrix}
10 & 0 \\
1 & 3
\end{bmatrix}
\]

Taxa de acerto: 92.85\%

Ainda assim, a acurária foi de 99.64\% com desvio padrão de 1.59\%.

\subsection{Íris}

No problema da Íris os resultados encontrados encontram-se acima de
93,33\% na taxa de acerto. Nos melhores testes, foram a Matrix de
Confusão:

\[
\begin{bmatrix}
20 & 1 \\
0 & 9
\end{bmatrix}
\]

Taxa de acerto: 96.66\%.

De forma geral, a acurácia foi de 95,83\% com desvio padrão de 1,48\%.

\section{Conclusão}

Apesar de elementar, o Perceptron Simples é um ótimo algoritmo de
classificação binária. Dado qualquer problema, ele é capaz de encontrar
uma regra de aprendizagem que garante encontrar uma solução ótima num
número finito de iterações.

Repositório com código-fonte:
\url{https://github.com/atilacamurca/rna-2018-1}

Link para download:
\url{https://github.com/atilacamurca/rna-2018-1/archive/master.zip}
