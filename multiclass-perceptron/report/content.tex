% pandoc-fignos: caption name
\renewcommand{\figurename}{Figura}

\section{Introdução}

O perceptron simples é capaz de resolver problemas binários, que podem
ser separados linearmente. Mas para problemas com mais de uma classe é
necessário adaptar o algoritmo, adicionando mais neurônios, em que cada
um prediz uma classe.

Além disso também é possível estender o algoritmo para incluir funções
não-lineares, como por exemplo sigmóide logística ou sigmóide tangente
hiberbólica. Redes com funções sigmóides podem aproximar uma função
não-linear contínua para uma acurácia arbitrária com uma única camada
escondida.

\section{Problemas}

\subsection{Íris}

O problema da Íris é a classificação de uma espécie de flor. Essa base
de dados é formada por 3 categorias: Setosa, Versicolor e Virgínica,
onde:

\begin{itemize}
\tightlist
\item
  Setosa é classificada como classe {[}1 0 0{]}, com 50 itens na base;
\item
  Versicolor é classificada como classe {[}0 1 0{]}, com 50 itens na
  base;
\item
  Virgínica é classificada como classe {[}0 0 1{]}, com 50 itens na
  base;
\end{itemize}

\section{Resultados}

\subsection{Íris}

No problema da Íris, usando rede perceptron com neurônios degrau, os
resultados encontrados encontram-se acima de 80,00\% na taxa de acerto.

Pior resultado:

\begin{verbatim}
Num. Pred corretas: 26 de 30
====  Sumário  =====
        Realização: 19
Matriz de Confusão: [10 0 0;3 4 3;0 0 10]
    Taxa de Acerto: 80
\end{verbatim}

Melhor resultado:

\begin{verbatim}
Num. Pred corretas: 30 de 30
====  Sumário  =====
        Realização: 3
Matriz de Confusão: [10 0 0;0 10 0;0 0 10]
    Taxa de Acerto: 100
\end{verbatim}

Sumário:

\begin{verbatim}
====  Sumário Geral  ====
        Acurácia: 92
   Desvio Padrão: 5.9628
\end{verbatim}

Para uma rede perceptron com neurônios que usam função de ativação
sigmóide logística os resultados encontram-se acima de 73\% na taxa de
acerto.

Pior resultado:

\begin{verbatim}
Num. Pred corretas: 22 de 30
====  Sumário  =====
        Realização: 20
Matriz de Confusão: [10 0 0;0 2 8;0 0 10]
    Taxa de Acerto: 73.3333
\end{verbatim}

Melhor resultado:

\begin{verbatim}
Num. Pred corretas: 28 de 30
====  Sumário  =====
        Realização: 14
Matriz de Confusão: [10 0 0;0 8 2;0 0 10]
    Taxa de Acerto: 93.3333
\end{verbatim}

Sumário:

\begin{verbatim}
====  Sumário Geral  ====
        Acurácia: 85.8333
   Desvio Padrão: 5.8114
\end{verbatim}

Para uma rede perceptron com neurônios que usam função de ativação
sigmóide tangente hiperbólica os resultados encontram-se acima de 73\%
na taxa de acerto.

Pior resultado:

\begin{verbatim}
Num. Pred corretas: 26 de 30
====  Sumário  =====
        Realização: 19
Matriz de Confusão: [10 0 0;0 7 3;0 1 9]
    Taxa de Acerto: 86.6667
\end{verbatim}

Melhor resultado:

\begin{verbatim}
Num. Pred corretas: 30 de 30
====  Sumário  =====
        Realização: 3
Matriz de Confusão: [10 0 0;0 10 0;0 0 10]
    Taxa de Acerto: 100
\end{verbatim}

Sumário:

\begin{verbatim}
====  Sumário Geral  ====
        Acurácia: 93.3333
   Desvio Padrão: 3.7463
\end{verbatim}

\section{Conclusão}

Apesar de elementar, o Perceptron Simples é um ótimo algoritmo de
classificação binária. Dado qualquer problema, ele é capaz de encontrar
uma regra de aprendizagem que garante encontrar uma solução ótima num
número finito de iterações.

Repositório com código-fonte:
\url{https://github.com/atilacamurca/rna-2018-1}

Link para download:
\url{https://github.com/atilacamurca/rna-2018-1/archive/master.zip}
